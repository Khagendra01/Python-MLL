{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load what we need from numpy, matplotlib\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# set numpy print precision to be 2 digits\n",
    "\n",
    "# thanks to professor veskler who helped me outside of the class to completely understand RL agent and make my eyes wide open, also he appreciated my small begineer like questions inside the class too so just a shout out to him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL:\n",
    "    def __init__(self, learningRate = .1, potentialToExplore = .1, discountFactor = .8):\n",
    "        self.learningRate = learningRate\n",
    "        self.potentialToExplore = potentialToExplore\n",
    "        self.discountFactor = discountFactor\n",
    "        self.stateActionQvalues = defaultdict(float)\n",
    "        self.trace = []\n",
    "        self.numberOfRing = 0\n",
    "        \n",
    "    def step(self, towers, towerWithRing, numberOfRing):     \n",
    "        self.numberOfRing = numberOfRing\n",
    "        self.towers = towers\n",
    "        action = self.rlAction( towers, towerWithRing ) \n",
    "        self.trace.append( ( towers, action ) )\n",
    "        reward = self.currentStateValue( towers )\n",
    "        self.updateState(towers, action, towerWithRing)\n",
    "        if reward:\n",
    "            self.learn(reward)\n",
    "        return action\n",
    "        \n",
    "    def rlAction(self, towers, towerWithRing):\n",
    "        if random.random() < self.potentialToExplore:\n",
    "            towerN = random.choice(towerWithRing)\n",
    "            pickRing = towers[towerN].pop()\n",
    "            towers[towerN].append(pickRing)\n",
    "            towerToPlace = towerN\n",
    "\n",
    "            while towerToPlace == towerN:\n",
    "                towerToPlace = towers.index(random.choice(towers))\n",
    "                popIt = towers[towerToPlace].pop()\n",
    "                if popIt is None:\n",
    "                    continue\n",
    "                towers[towerToPlace].append(popIt)\n",
    "                if popIt > pickRing and towerToPlace != towerN:\n",
    "                    return towerN, pickRing, towerToPlace\n",
    "        else:\n",
    "            succeed = False\n",
    "            bestValue = -1\n",
    "            for towerN in towerWithRing:\n",
    "                tower = towers[towerN]\n",
    "                pickIt = tower.pop()\n",
    "                tower.append(pickIt)\n",
    "                if pickIt is None:\n",
    "                    continue\n",
    "                for toTowerV in towers:\n",
    "                    toTower = towers.index(toTowerV)\n",
    "                    if towerN != toTower:\n",
    "                        stateValue = self.stateActionQvalues[\n",
    "                            (tuple(tuple(x) for x in towers), towerN, pickIt, toTower)\n",
    "                        ]\n",
    "                        if stateValue > bestValue:\n",
    "                            actionTaken = towerN, pickIt, toTower\n",
    "                            bestValue = stateValue\n",
    "                            succeed = True\n",
    "            if succeed:\n",
    "                return actionTaken\n",
    "\n",
    "            \n",
    "    def currentStateValue( self, towers ):           \n",
    "        if len(towers[len(towers) - 1]) == self.numberOfRing:\n",
    "            return 1\n",
    "        \n",
    "    def updateState(self, towers, action, towerWithRing):\n",
    "        towerN, pickIt, toTower = action\n",
    "        towers[towerN].remove(pickIt)\n",
    "        towers[toTower].append(pickIt)\n",
    "        if toTower not in towerWithRing:\n",
    "            towerWithRing.append(toTower)   \n",
    "    \n",
    "    def learn(self, reward):\n",
    "        self.trace.reverse()\n",
    "        for stateaction in self.trace:\n",
    "            eV = self.stateActionQvalues[stateaction]\n",
    "            self.stateActionQvalues[stateaction] += self.learningRate * ( reward - eV )\n",
    "            reward *= self.discountFactor\n",
    "        self.trace = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken: (0, 3, 1)\n",
      "Updated towers: [[1, 2], [3], [1, 2]]\n"
     ]
    }
   ],
   "source": [
    "towers = [[1, 2, 3], [], [1,2]]\n",
    "towerWithRing = [0]\n",
    "\n",
    "# import random \n",
    "# print(random.choice(towers))\n",
    "rl_agent = RL()\n",
    "action = rl_agent.step(towers, towerWithRing, 3)\n",
    "print(\"Action taken:\", action)\n",
    "print(\"Updated towers:\", towers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
